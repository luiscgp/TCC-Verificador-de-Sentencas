{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luid/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pathlib, glob\n",
    "from haystack.nodes import PDFToTextConverter, PreProcessor,EmbeddingRetriever\n",
    "from haystack.nodes.base import BaseComponent\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.pipelines import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)ce_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 188kB/s]\n",
      "Downloading (…)5f450/.gitattributes: 100%|██████████| 690/690 [00:00<00:00, 2.77MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 205kB/s]\n",
      "Downloading (…)/2_Dense/config.json: 100%|██████████| 114/114 [00:00<00:00, 185kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.58M/1.58M [00:00<00:00, 2.12MB/s]\n",
      "Downloading (…)966465f450/README.md: 100%|██████████| 2.38k/2.38k [00:00<00:00, 3.83MB/s]\n",
      "Downloading (…)6465f450/config.json: 100%|██████████| 556/556 [00:00<00:00, 916kB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 201kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 539M/539M [01:09<00:00, 7.81MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 201kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 311kB/s]\n",
      "Downloading (…)5f450/tokenizer.json: 100%|██████████| 1.96M/1.96M [00:00<00:00, 2.16MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 452/452 [00:00<00:00, 1.85MB/s]\n",
      "Downloading (…)966465f450/vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 2.98MB/s]\n",
      "Downloading (…)465f450/modules.json: 100%|██████████| 341/341 [00:00<00:00, 706kB/s]\n",
      "/home/luid/.local/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "document_store = FAISSDocumentStore(similarity=\"cosine\")\n",
    "converter = PDFToTextConverter(remove_numeric_tables=True, valid_languages=[\"pt\"])\n",
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"sentence\",\n",
    "    split_respect_sentence_boundary=False)\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store, \n",
    "    embedding_model=\"sentence-transformers/distiluse-base-multilingual-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/luid/TCC-Verificador-de-Sentencas/SentenceBert.ipynb Célula 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/luid/TCC-Verificador-de-Sentencas/SentenceBert.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m indexing_pipeline \u001b[39m=\u001b[39m Pipeline()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luid/TCC-Verificador-de-Sentencas/SentenceBert.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m indexing_pipeline\u001b[39m.\u001b[39madd_node(component\u001b[39m=\u001b[39mconverter, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTextConverter\u001b[39m\u001b[39m\"\u001b[39m, inputs\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mFile\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luid/TCC-Verificador-de-Sentencas/SentenceBert.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m indexing_pipeline\u001b[39m.\u001b[39madd_node(component\u001b[39m=\u001b[39mpreprocessor, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPreProcessor\u001b[39m\u001b[39m\"\u001b[39m, inputs\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mTextConverter\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_node(component=converter, name=\"TextConverter\", inputs=[\"File\"])\n",
    "indexing_pipeline.add_node(component=preprocessor, name=\"PreProcessor\", inputs=[\"TextConverter\"])\n",
    "indexing_pipeline.add_node(component=document_store, name=\"DocumentStore\", inputs=[\"TextConverter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_index = [f for f in pathlib.Path().glob(\"./ETL/paper*.pdf\")]\n",
    "indexing_pipeline.run(file_paths = files_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = PDFToTextConverter(\n",
    "    remove_numeric_tables=True,\n",
    "    valid_languages=[\"pt\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PDFToTextConverter\n",
    "import langdetect\n",
    "\n",
    "converter = PDFToTextConverter(\n",
    "    remove_numeric_tables=True,\n",
    "    valid_languages=[\"pt\"]\n",
    ")\n",
    "docs = converter.convert(file_path=\"./ETL/paper1.pdf\", meta=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"sentence\",\n",
    "    split_respect_sentence_boundary=False)\n",
    "\n",
    "docs_default = preprocessor.process(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for doc in docs_default:\n",
    "    sentences.append(doc[\"content\"].split(\". \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"n_files_input: {len(docs_default)}\\nn_docs_output: {len(docs_default)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar disponibilidade de placa gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codifique as sentenças usando o modelo\n",
    "embeddings = model.encode(sentences, show_progress_bar=True, convert_to_tensor=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = \"A amazôniza azul não possui extensão de 30000 km^2\"\n",
    "new_embedding = model.encode([new_sentence], convert_to_tensor=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_embeddings = embeddings.cpu().numpy()\n",
    "np_input = new_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Calcule a similaridade de cosseno entre a nova sentença e as sentenças existentes\n",
    "similarities = util.pytorch_cos_sim(new_embedding, embeddings)[0]\n",
    "\n",
    "# Encontre os índices das sentenças mais similares (N sentenças)\n",
    "N = 5\n",
    "most_similar_indices = (-similarities).argsort()[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in most_similar_indices:\n",
    "    print(sentences[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
